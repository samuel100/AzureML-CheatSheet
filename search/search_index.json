{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Azure ML Cheat Sheet Basics Workspace Instantiate workspace. from azureml.core import Workspace ws = Workspace . from_config () VS Code snippet Workspaces are a foundational object used throughout AML and are used in the constructors of many other classes. In the following examples we frequently omit the workspace object instantiation and simply refer to ws . See the workspaces page for more ways to instantiate a workspace. Datastore Each workspace comes with a default datastore. ds = ws . get_default_datastore () Any datastore that is registered to workspace can be accessed by name from azureml.core import Datastore ds = Datastore . get ( ws , \"<name-of-registered-datastore>\" ) To register a store via a SAS token: ds = Datastore . register_azure_blob_container ( workspace = ws , datastore_name = \"<datastore-name>\" , container_name = \"<container-name>\" , account_name = \"<account-name>\" , sas_token = \"<sas-token>\" , ) VS Code snippet For more ways authentication options and for different underlying storage see the AML documentation on Datastores . Compute Targets Compute targets are an AML abstraction around the concept of a compute resource ranging from your local machine to an (auto-scaling) cluster of Azure VMs. To use an existing compute target: from azureml.core import ComputeTarget compute_target = ComputeTarget ( workspace = ws , name = \"<compute-name>\" ) For example, to create a new cluster of between 0 and 4 \"Standard_NC24rs_v3\" VMs, from azureml.core import ComputeTarget from azureml.core.compute import AmlCompute compute_config = AmlCompute . provisioning_configuration ( vm_size = \"Standard_NC24rs_v3\" , min_nodes = 0 , max_nodes = 4 , ) compute_target = ComputeTarget . create ( ws , \"<compute-name>\" , compute_config ) compute_target . wait_for_completion ( show_output = True ) See the Compute Targets page for more examples. Running Scripts in AML This section shows how to run a script on AML. Suppose you are in possession of a script primes.py . # primes.py import argparse parser = argparse . ArgumentParser () parser . add_argument ( '--upper' , type = int , help = \"Find all primes below this.\" ) args = parser . parse_args () numbers = list ( range ( 0 , args . upper )) for prime in numbers : if prime < 2 : continue elif prime > args . upper ** 0.5 : break for i in range ( prime ** 2 , args . upper , prime ): numbers [ i ] = 0 print ([ x for x in numbers if x > 1 ]) Experiments An experiment is used as an organizational principle, storing run history and tracking metrics. Get or create an experiment: from azureml.core import Experiment exp = Experiment ( ws , \"<experiment-name>\" ) Use experiments to submit run configurations (see ScriptRunConfig section): run = exp . submit ( config ) ScriptRunConfig A typical directory may have the following structure: # run.py from azureml.core import Workspace , Experiment , ScriptRunConfig # get workspace ws = Workspace . from_config () # get/create experiment exp = Experiment ( ws , 'Primes' ) # set up script run configuration config = ScriptRunConfig ( source_directory = '.' , script = 'primes.py' , arguments = [ '--upper' , 100 ], ) # submit script to AML run = exp . submit ( config ) print ( run . get_portal_url ()) # link to ml.azure.com This example assumes that primes.py is in the current working directory. In this example since no compute target was specified the script is running on local compute i.e., it runs on the machine that kicked off the job. We can get this code to run remotely in Azure by giving it a compute target. # set up script run configuration config = ScriptRunConfig ( source_directory = '.' , script = 'primes.py' , arguments = [ '--upper' , 100 ], ) config . run_config . target = \"<name-of-compute-target>\" exp . submit ( config ) Environments (Running Scripts) In the scenario that your script requires certain python libraries to run you can provide an AML environment object (see Environments section) to the ScriptRunConfig env = Environment ( ws , '<environment-name>' ) config . run_config . environment = env Environments Environment We can use a Conda/pip to define AML environments. Conda (env.yml) # env.yml name: my-env channels: - defaults - conda-forge dependencies: - numpy - pandas - scipy - scikit-learn - pip - python=3.6 - jupyter - ipykernel - pip: - azureml-sdk==1.8.0 - torch - transformers==2.11.0 pip (requirements.txt) # requirement.txt azureml-dataprep==1.8.3 azureml-sdk==1.8.0 flake8==3.7.9 numpy==1.18.5 pycodestyle==2.5.0 torch==1.5.1 tqdm==4.48.0 transformers==2.11.0 to create and register an AML environment that can be cached, versioned and reused between different experiments, runs and compute targets. Create the AML environment Conda from azureml.core import Environment my_env = Environment . from_conda_specification ( name = '<environment-name>' , file_path = '<path-to-env.yml>' , ) pip from azureml.core import Environment my_env = Environment . from_pip_specification ( name = '<environment-name>' , file_path = '<path-to-requirements.txt>' , ) To register this environment with the workspace my_env . register ( ws ) To view all environments registered to a workspace from azureml.core import Environment registered_environments = Environment . list ( ws )","title":"Cheatsheet"},{"location":"#azure-ml-cheat-sheet","text":"","title":"Azure ML Cheat Sheet"},{"location":"#basics","text":"","title":"Basics"},{"location":"#workspace","text":"Instantiate workspace. from azureml.core import Workspace ws = Workspace . from_config () VS Code snippet Workspaces are a foundational object used throughout AML and are used in the constructors of many other classes. In the following examples we frequently omit the workspace object instantiation and simply refer to ws . See the workspaces page for more ways to instantiate a workspace.","title":"Workspace"},{"location":"#datastore","text":"Each workspace comes with a default datastore. ds = ws . get_default_datastore () Any datastore that is registered to workspace can be accessed by name from azureml.core import Datastore ds = Datastore . get ( ws , \"<name-of-registered-datastore>\" ) To register a store via a SAS token: ds = Datastore . register_azure_blob_container ( workspace = ws , datastore_name = \"<datastore-name>\" , container_name = \"<container-name>\" , account_name = \"<account-name>\" , sas_token = \"<sas-token>\" , ) VS Code snippet For more ways authentication options and for different underlying storage see the AML documentation on Datastores .","title":"Datastore"},{"location":"#compute-targets","text":"Compute targets are an AML abstraction around the concept of a compute resource ranging from your local machine to an (auto-scaling) cluster of Azure VMs. To use an existing compute target: from azureml.core import ComputeTarget compute_target = ComputeTarget ( workspace = ws , name = \"<compute-name>\" ) For example, to create a new cluster of between 0 and 4 \"Standard_NC24rs_v3\" VMs, from azureml.core import ComputeTarget from azureml.core.compute import AmlCompute compute_config = AmlCompute . provisioning_configuration ( vm_size = \"Standard_NC24rs_v3\" , min_nodes = 0 , max_nodes = 4 , ) compute_target = ComputeTarget . create ( ws , \"<compute-name>\" , compute_config ) compute_target . wait_for_completion ( show_output = True ) See the Compute Targets page for more examples.","title":"Compute Targets"},{"location":"#running-scripts-in-aml","text":"This section shows how to run a script on AML. Suppose you are in possession of a script primes.py . # primes.py import argparse parser = argparse . ArgumentParser () parser . add_argument ( '--upper' , type = int , help = \"Find all primes below this.\" ) args = parser . parse_args () numbers = list ( range ( 0 , args . upper )) for prime in numbers : if prime < 2 : continue elif prime > args . upper ** 0.5 : break for i in range ( prime ** 2 , args . upper , prime ): numbers [ i ] = 0 print ([ x for x in numbers if x > 1 ])","title":"Running Scripts in AML"},{"location":"#experiments","text":"An experiment is used as an organizational principle, storing run history and tracking metrics. Get or create an experiment: from azureml.core import Experiment exp = Experiment ( ws , \"<experiment-name>\" ) Use experiments to submit run configurations (see ScriptRunConfig section): run = exp . submit ( config )","title":"Experiments"},{"location":"#scriptrunconfig","text":"A typical directory may have the following structure: # run.py from azureml.core import Workspace , Experiment , ScriptRunConfig # get workspace ws = Workspace . from_config () # get/create experiment exp = Experiment ( ws , 'Primes' ) # set up script run configuration config = ScriptRunConfig ( source_directory = '.' , script = 'primes.py' , arguments = [ '--upper' , 100 ], ) # submit script to AML run = exp . submit ( config ) print ( run . get_portal_url ()) # link to ml.azure.com This example assumes that primes.py is in the current working directory. In this example since no compute target was specified the script is running on local compute i.e., it runs on the machine that kicked off the job. We can get this code to run remotely in Azure by giving it a compute target. # set up script run configuration config = ScriptRunConfig ( source_directory = '.' , script = 'primes.py' , arguments = [ '--upper' , 100 ], ) config . run_config . target = \"<name-of-compute-target>\" exp . submit ( config )","title":"ScriptRunConfig"},{"location":"#environments-running-scripts","text":"In the scenario that your script requires certain python libraries to run you can provide an AML environment object (see Environments section) to the ScriptRunConfig env = Environment ( ws , '<environment-name>' ) config . run_config . environment = env","title":"Environments (Running Scripts)"},{"location":"#environments","text":"","title":"Environments"},{"location":"#environment","text":"We can use a Conda/pip to define AML environments. Conda (env.yml) # env.yml name: my-env channels: - defaults - conda-forge dependencies: - numpy - pandas - scipy - scikit-learn - pip - python=3.6 - jupyter - ipykernel - pip: - azureml-sdk==1.8.0 - torch - transformers==2.11.0 pip (requirements.txt) # requirement.txt azureml-dataprep==1.8.3 azureml-sdk==1.8.0 flake8==3.7.9 numpy==1.18.5 pycodestyle==2.5.0 torch==1.5.1 tqdm==4.48.0 transformers==2.11.0 to create and register an AML environment that can be cached, versioned and reused between different experiments, runs and compute targets. Create the AML environment Conda from azureml.core import Environment my_env = Environment . from_conda_specification ( name = '<environment-name>' , file_path = '<path-to-env.yml>' , ) pip from azureml.core import Environment my_env = Environment . from_pip_specification ( name = '<environment-name>' , file_path = '<path-to-requirements.txt>' , ) To register this environment with the workspace my_env . register ( ws ) To view all environments registered to a workspace from azureml.core import Environment registered_environments = Environment . list ( ws )","title":"Environment"},{"location":"templates/","text":"Templates Introduction Cookiecutter is a simple command-line tool that allows you to quickly create new projects from pre-defined templates. Let's see it in action! First go ahead and get cookiecutter using your environment manager of choice, for example: pip install cookiecutter Then give this repo a home cd ~/repos # or wherever your repos call home :-) git clone <this-repo> To create a new project from the ScriptRunConfig template for example, simply run cookiecutter path/to/cheatsheet/repo/templates/ScriptRunConfig See ScriptRunConfig for more details for this template. Templates ScriptRunConfig: Create a project to run a script in AML making use of the ScriptRunConfig class. This template is well suited for smaller projects and is especially handy for testing. ScriptRunConfig Cookiecutter template for setting up an AML ScriptRunConfig used to run your script in Azure. Usage Run the cookiecutter command cookiecutter <path/to/cookiecutter/templates>/ScriptRunConfig to create a new ScriptRunConfig project. Note. Install with pip install cookiecutter (see cookiecutter docs for more installation options) You will be prompted for the following: directory_name : The desired name of the directory (default: \"aml-src-script\") script_name : The name of the python script to be run in Azure (default: \"script\") subscription_id : Your Azure Subscription ID resource_group : Your Azure resource group name workspace_name : Your Azure ML workspace name compute_target_name : The name of the Azure ML compute target to run the script on (default: \"local\", will run on your box) Cookiecutter creates a new project with the following layout. {directory_name}/ {script_name}.py # the script you want to run in the cloud run.py # wraps your script in ScriptRunConfig to send to Azure config.json # your Azure ML metadata readme.md # this readme file! See ScriptRunConfig for more options and details on configuring runs.","title":"Templates"},{"location":"templates/#templates","text":"","title":"Templates"},{"location":"templates/#introduction","text":"Cookiecutter is a simple command-line tool that allows you to quickly create new projects from pre-defined templates. Let's see it in action! First go ahead and get cookiecutter using your environment manager of choice, for example: pip install cookiecutter Then give this repo a home cd ~/repos # or wherever your repos call home :-) git clone <this-repo> To create a new project from the ScriptRunConfig template for example, simply run cookiecutter path/to/cheatsheet/repo/templates/ScriptRunConfig See ScriptRunConfig for more details for this template.","title":"Introduction"},{"location":"templates/#templates_1","text":"ScriptRunConfig: Create a project to run a script in AML making use of the ScriptRunConfig class. This template is well suited for smaller projects and is especially handy for testing.","title":"Templates"},{"location":"templates/#scriptrunconfig","text":"Cookiecutter template for setting up an AML ScriptRunConfig used to run your script in Azure.","title":"ScriptRunConfig"},{"location":"templates/#usage","text":"Run the cookiecutter command cookiecutter <path/to/cookiecutter/templates>/ScriptRunConfig to create a new ScriptRunConfig project. Note. Install with pip install cookiecutter (see cookiecutter docs for more installation options) You will be prompted for the following: directory_name : The desired name of the directory (default: \"aml-src-script\") script_name : The name of the python script to be run in Azure (default: \"script\") subscription_id : Your Azure Subscription ID resource_group : Your Azure resource group name workspace_name : Your Azure ML workspace name compute_target_name : The name of the Azure ML compute target to run the script on (default: \"local\", will run on your box) Cookiecutter creates a new project with the following layout. {directory_name}/ {script_name}.py # the script you want to run in the cloud run.py # wraps your script in ScriptRunConfig to send to Azure config.json # your Azure ML metadata readme.md # this readme file! See ScriptRunConfig for more options and details on configuring runs.","title":"Usage"},{"location":"more/compute-targets/","text":"Compute Targets The following will first attempt to retrieve an existing compute target by its name. If the compute does not exist it will create the cluster. from azureml.core import ComputeTarget from azureml.core.compute import AmlCompute from azureml.core.compute_target import ComputeTargetException compute_name = \"<compute-name>\" try : compute_target = ComputeTarget ( workspace = ws , name = compute_name ) print ( f 'Found existing compute target: { compute_name } .' ) except ComputeTargetException : print ( 'Creating a new compute target...' ) compute_target = ComputeTarget . create ( ws , compute_name , compute_config ) compute_target . wait_for_completion ( show_output = True )","title":"Compute Targets"},{"location":"more/compute-targets/#compute-targets","text":"The following will first attempt to retrieve an existing compute target by its name. If the compute does not exist it will create the cluster. from azureml.core import ComputeTarget from azureml.core.compute import AmlCompute from azureml.core.compute_target import ComputeTargetException compute_name = \"<compute-name>\" try : compute_target = ComputeTarget ( workspace = ws , name = compute_name ) print ( f 'Found existing compute target: { compute_name } .' ) except ComputeTargetException : print ( 'Creating a new compute target...' ) compute_target = ComputeTarget . create ( ws , compute_name , compute_config ) compute_target . wait_for_completion ( show_output = True )","title":"Compute Targets"},{"location":"more/datastore/","text":"","title":"Datastore"},{"location":"more/environment/","text":"Environment From conda/pip files We can use a Conda/pip to define AML environments. Conda (env.yml) # env.yml name: my-env channels: - defaults - conda-forge dependencies: - numpy - pandas - scipy - scikit-learn - pip - python=3.6 - jupyter - ipykernel - pip: - azureml-sdk==1.8.0 - torch - transformers==2.11.0 pip (requirements.txt) # requirement.txt azureml-dataprep==1.8.3 azureml-sdk==1.8.0 flake8==3.7.9 numpy==1.18.5 pycodestyle==2.5.0 torch==1.5.1 tqdm==4.48.0 transformers==2.11.0 to create and register an AML environment that can be cached, versioned and reused between different experiments, runs and compute targets. Create the AML environment Conda from azureml.core import Environment my_env = Environment . from_conda_specification ( name = '<environment-name>' , file_path = '<path-to-env.yml>' , ) pip from azureml.core import Environment my_env = Environment . from_pip_specification ( name = '<environment-name>' , file_path = '<path-to-requirements.txt>' , ) To register this environment with the workspace my_env . register ( ws ) To view all environments registered to a workspace from azureml.core import Environment registered_environments = Environment . list ( ws ) Specifying dependencies TODO","title":"Environment"},{"location":"more/environment/#environment","text":"","title":"Environment"},{"location":"more/environment/#from-condapip-files","text":"We can use a Conda/pip to define AML environments. Conda (env.yml) # env.yml name: my-env channels: - defaults - conda-forge dependencies: - numpy - pandas - scipy - scikit-learn - pip - python=3.6 - jupyter - ipykernel - pip: - azureml-sdk==1.8.0 - torch - transformers==2.11.0 pip (requirements.txt) # requirement.txt azureml-dataprep==1.8.3 azureml-sdk==1.8.0 flake8==3.7.9 numpy==1.18.5 pycodestyle==2.5.0 torch==1.5.1 tqdm==4.48.0 transformers==2.11.0 to create and register an AML environment that can be cached, versioned and reused between different experiments, runs and compute targets. Create the AML environment Conda from azureml.core import Environment my_env = Environment . from_conda_specification ( name = '<environment-name>' , file_path = '<path-to-env.yml>' , ) pip from azureml.core import Environment my_env = Environment . from_pip_specification ( name = '<environment-name>' , file_path = '<path-to-requirements.txt>' , ) To register this environment with the workspace my_env . register ( ws ) To view all environments registered to a workspace from azureml.core import Environment registered_environments = Environment . list ( ws )","title":"From conda/pip files"},{"location":"more/environment/#specifying-dependencies","text":"TODO","title":"Specifying dependencies"},{"location":"more/workspace/","text":"Workspace Instantiate workspace. from azureml.core import Workspace ws = Workspace . from_config () This examples reads the workspace from a config.json file, the contents of which are of the form { \"subscription_id\" : <subscription-id> , \"resource_group\" : <resource-group> , \"workspace_name\" : <workspace-name> } Alternatively you can provide these values directly: from azureml.core import Workspace ws = Workspace . get ( name = \"<workspace-name>\" , subscription_id = \"<subscription-id>\" , resource_group = \"<resource-group>\" , )","title":"Workspace"},{"location":"more/workspace/#workspace","text":"Instantiate workspace. from azureml.core import Workspace ws = Workspace . from_config () This examples reads the workspace from a config.json file, the contents of which are of the form { \"subscription_id\" : <subscription-id> , \"resource_group\" : <resource-group> , \"workspace_name\" : <workspace-name> } Alternatively you can provide these values directly: from azureml.core import Workspace ws = Workspace . get ( name = \"<workspace-name>\" , subscription_id = \"<subscription-id>\" , resource_group = \"<resource-group>\" , )","title":"Workspace"},{"location":"vs-code-snippets/snippets/","text":"VS Code Snippets We have compiled a collection of VS code snippets designed to make it easy to work with Azure ML. To add these snippets to your VS Code: ctrl+shift+p > Type \"Configure user snippets\" > Select python.json . All of these snippets are available here: python.json Basic core imports \"Basic core imports\" : { \"prefix\" : \"workspace-imports-creation\" , \"body\" : [ \"from azureml.core import Workspace, Experiment, Run, RunConfiguration, ComputeTarget$1\" , \"$0\" ], \"description\" : \"Import essential packages\" } Pipeline imports \"Pipeline Imports\" : { \"prefix\" : \"pipeline-imports\" , \"body\" : [ \"from azureml.pipeline.core import Pipeline, PipelineData, PipelineParameter\" , \"from azureml.pipeline.steps import PythonScriptStep$1\" , \"$0\" ], \"description\" : \"Basic imports for pipeline\" } Create AML Workspace from config \"Create AML Workspace from config\" : { \"prefix\" : [ \"workspace-quick\" , \"fromconfig\" , \"from-config\" ], \"body\" : [ \"ws = Workspace.from_config()\" , \"$0\" ], \"description\" : \"Default workspace creation\" } Create AML Workspace from config and auth \"Create AML Workspace from config and auth\" : { \"prefix\" : \"workspace-from-config-auth\" , \"body\" : [ \"from azureml.core.authentication import InteractiveLoginAuthentication\" , \"config = {'subscription_id':'$1',\" , \"'resource_group':'$2',\" , \"'workspace_name' :'$3'}\" , \"auth = InteractiveLoginAuthentication()\" , \"ws = Workspace(**config,auth = auth)\" , \"$0\" ], \"description\" : \"Create workspace from config and auth\" } Register Azure Blob Container From SAS \"Register Azure Blob Container From SAS\" : { \"prefix\" : [ \"datastore-register-blob-sas\" , \"reg-blob-sas\" ], \"body\" : [ \"ds = Datastore.register_azure_blob_container(\" \" workspace='$1',\" \" datastore_name='$2',\" , \" container_name='$3',\" , \" account_name='$4',\" , \" sas_token='$5',\" , \")\" \"$0\" ], \"description\" : \"Register Azure Blob container to workspace via SAS\" } Create Compute Cluster with SSH \"Create Compute Cluster with SSH\" : { \"prefix\" : [ \"create-compute-cluster-ssh\" ], \"body\" : [ \"from azureml.core.compute import AmlCompute\" , \"from azureml.core.compute_target import ComputeTargetException\" , \"ssh_public_key = '$1'\" , \"compute_config = AmlCompute.provisioning_configuration(vm_size='$4',min_nodes=$5, max_nodes=$6,admin_username='$7',admin_user_ssh_key=ssh_public_key,vm_priority='${8|lowpriority,dedicated|}',remote_login_port_public_access='Enabled')\" , \"cluster$0 = ComputeTarget.create(workspace=$9, name='$10', compute_config)\" ], \"description\" : \"Create compute cluster with SSH enabled\" }","title":"VS Code Snippets"},{"location":"vs-code-snippets/snippets/#vs-code-snippets","text":"We have compiled a collection of VS code snippets designed to make it easy to work with Azure ML. To add these snippets to your VS Code: ctrl+shift+p > Type \"Configure user snippets\" > Select python.json . All of these snippets are available here: python.json","title":"VS Code Snippets"},{"location":"vs-code-snippets/snippets/#basic-core-imports","text":"\"Basic core imports\" : { \"prefix\" : \"workspace-imports-creation\" , \"body\" : [ \"from azureml.core import Workspace, Experiment, Run, RunConfiguration, ComputeTarget$1\" , \"$0\" ], \"description\" : \"Import essential packages\" }","title":"Basic core imports"},{"location":"vs-code-snippets/snippets/#pipeline-imports","text":"\"Pipeline Imports\" : { \"prefix\" : \"pipeline-imports\" , \"body\" : [ \"from azureml.pipeline.core import Pipeline, PipelineData, PipelineParameter\" , \"from azureml.pipeline.steps import PythonScriptStep$1\" , \"$0\" ], \"description\" : \"Basic imports for pipeline\" }","title":"Pipeline imports"},{"location":"vs-code-snippets/snippets/#create-aml-workspace-from-config","text":"\"Create AML Workspace from config\" : { \"prefix\" : [ \"workspace-quick\" , \"fromconfig\" , \"from-config\" ], \"body\" : [ \"ws = Workspace.from_config()\" , \"$0\" ], \"description\" : \"Default workspace creation\" }","title":"Create AML Workspace from config"},{"location":"vs-code-snippets/snippets/#create-aml-workspace-from-config-and-auth","text":"\"Create AML Workspace from config and auth\" : { \"prefix\" : \"workspace-from-config-auth\" , \"body\" : [ \"from azureml.core.authentication import InteractiveLoginAuthentication\" , \"config = {'subscription_id':'$1',\" , \"'resource_group':'$2',\" , \"'workspace_name' :'$3'}\" , \"auth = InteractiveLoginAuthentication()\" , \"ws = Workspace(**config,auth = auth)\" , \"$0\" ], \"description\" : \"Create workspace from config and auth\" }","title":"Create AML Workspace from config and auth"},{"location":"vs-code-snippets/snippets/#register-azure-blob-container-from-sas","text":"\"Register Azure Blob Container From SAS\" : { \"prefix\" : [ \"datastore-register-blob-sas\" , \"reg-blob-sas\" ], \"body\" : [ \"ds = Datastore.register_azure_blob_container(\" \" workspace='$1',\" \" datastore_name='$2',\" , \" container_name='$3',\" , \" account_name='$4',\" , \" sas_token='$5',\" , \")\" \"$0\" ], \"description\" : \"Register Azure Blob container to workspace via SAS\" }","title":"Register Azure Blob Container From SAS"},{"location":"vs-code-snippets/snippets/#create-compute-cluster-with-ssh","text":"\"Create Compute Cluster with SSH\" : { \"prefix\" : [ \"create-compute-cluster-ssh\" ], \"body\" : [ \"from azureml.core.compute import AmlCompute\" , \"from azureml.core.compute_target import ComputeTargetException\" , \"ssh_public_key = '$1'\" , \"compute_config = AmlCompute.provisioning_configuration(vm_size='$4',min_nodes=$5, max_nodes=$6,admin_username='$7',admin_user_ssh_key=ssh_public_key,vm_priority='${8|lowpriority,dedicated|}',remote_login_port_public_access='Enabled')\" , \"cluster$0 = ComputeTarget.create(workspace=$9, name='$10', compute_config)\" ], \"description\" : \"Create compute cluster with SSH enabled\" }","title":"Create Compute Cluster with SSH"}]}