{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Azure ML Cheat Sheet Basic Objects Workspace Creating a new Workspace To create a new Workspace : from azureml.core import Workspace ws = Workspace . create ( name = '<my-workspace-name>' , resource_group = '<my-resource-group>' , subscription_id = '<azure-subscription-id>' , location = '<azure-region>' , # e.g. 'eastus2' create_resource_group =< True / False > , # default:True sku = 'basic/enterprise' , # default:'basic' exists_ok =< True / False > , # default:False ) Supported Azure Regions See list of supported Azure regions here Write the workspace Azure Resource Manager (ARM) properties to a config file: ws . write_config ( path = '.azureml' , file_name = 'config.json' ) Workspace ARM properties can be loaded later using from_config() method. The path defaults to '.azureml/' and the file_name defaults to 'config.json'. Instantiate a Workspace Instantiate a workspace with the explicit Azure Resource Manager (ARM) properties: from azureml.core import Workspace ws = Workspace . get ( subscription_id = '<subscription-id>' , resource_group = '<resource-group>' , workspace_name = '<workspace-name>' , ) Instantiate a workspace from config file: from azureml.core import Workspace ws = Workspace . from_config ( path = '.azureml' ) # read your aml credentials from config.json and instantiate # Workspace object from_config search path By default, from_config() will search for a file named config.json in the current and parent directories and in any directory named .azureml therein. Otherwise the path and _file_name need to be provided. Delete a Workspace To delete an Azure Machine Learning workspace: ws . delete ( delete_dependent_resources = False , # delete all resources associated to the ws no_wait = False , # whether to wait for the deletion to complete ) Workspaces Workspaces are a foundational object used throughout AML and are used in the constructors of many other classes. In the following examples we frequently omit the workspace object instantiation and simply refer to ws . See the workspaces page for more ways to instantiate a workspace. Experiment An experiment is used as an organizational principle, storing run history and tracking metrics. Get all experiments within a workspace from azureml.core import Experiment experiments = Experiment . list ( ws , tags = None ) # return list[Experiment] Get or create an experiment from azureml.core import Experiment exp = Experiment ( ws , '<experiment-name>' ) If the experiment is not found in the workspace, a new experiment is created. Experiment names Experiment name must be 3-36 characters, start with a letter or a number, and can only contain letters, numbers, underscores, and dashes. Manage experiments Archive an experiment: exp . archive () Reactivate an experiment: exp . reactivate () Rename an experiment: exp = Experiment ( ws , name = '<exp-name>' ) exp . archive () exp . reactivate ( new_name = '<new-name>' ) Get all runs within an experiment Get a generator of all the runs contained in an experiment: exp . get_runs () # return list[Run] Get only runs of a certain type or with certain tags: exp . get_runs ( type = 'hyperdrive' , tags = { 'modifiedBy' : 'Master CI' }) # return list[Run] Run types Run type (str) indicates how the run was created. Examples include 'hyperdrive' or 'azureml.scriptrun', but can be extended with custom types. Get run include child runs: exp . get_runs ( include_children = True ) # return list[Run] Tag an experiment Tags on an experiment are stored in a dictionary with string keys and string values. Tag an experiment: exp . tag ( '' ) exp . tag ( 'DeploymentCandidate' ) exp . tag ( 'modifiedBy' , 'Master CI' ) exp . tag ( 'modifiedBy' , 'release pipeline' ) # careful, tags are mutable OR: # add a set of tags by providing Dict[str,str] exp . set_tags ({ 'modifiedBy' : 'Master CI' , 'area' : 'nlp' }) Run A run represents a single trial of an experiment. Runs are used to monitor the asynchronous execution of a trial, log metrics and store output of the trial, and to analyze results and access artifacts generated by the trial. Run IDs A unique run_id is automatically generated for each run. Create a run There are multiple ways to create a run. For example: Interactive run Create interactive runs in an interactive scenario e.g. Jupyter notebooks. from azureml.core import Experiment exp = Experiment ( ws , \"<experiment-name>\" ) # get or create experiment run = exp . start_logging () # start interactive run result = my_function () # do some things... run . log ( 'result' , result ) # log the results to the run run . complete () # stop the interactive run Logging See Logging . From configuration To submit a run asynchronously - either to local compute or to cloud compute - define a configuration. See \" Running Scripts in AML \" for details. from azureml.core import Experiment from azureml.core import ScriptRunConfig exp = Experiment ( ws , \"<experiment-name>\" ) config = ScriptRunConfig ( ... ) # provide code, compute, environments, etc. run = exp . submit ( config ) ScriptRunConfig See Running Scripts in AML . Get list of runs List of runs within an experiment: from azureml.core import Experiment from azureml.core import Run exp = Experiment ( ws , name = '<experiment-name>' ) runs = Run . list ( exp ) # return Generator[Run] List of runs within a compute target: from azureml.core import ComputeTarget from azureml.core import Run target = ComputeTarget ( ws , name = '<target-name>' ) runs_on_target = Run . list_by_compute ( target ) # return Generator[Run] Filtered list of runs: from azureml.core import Run type_ = 'hyperdrive' tags = { 'area' : 'nlp' } status = 'Completed' runs = Run . list ( exp , type = type_ , tags = tags , status = status ) # return Generator[Run] Run types Run type (str) indicates how the run was created. Examples include 'hyperdrive' or 'azureml.scriptrun', but can be extended with custom types. Managing runs Get run status: run . get_status () Cancel a run: run . cancel () Mark run as failed: run . fail ( error_details = 'userError' ) # error details can be str run . fail ( error_details = TypeError ) # or BaseException Get run details Get the definition, status information, current log files, and other details of the run. run . get_details () # return dict[str, str] Keys: runId , target , status , startTimeUtc , endTimeUtc , properties , datasets , logfiles . For more details see the method signature . Compute Target Compute targets are an AML abstraction around the concept of a compute resource. This can range from your local machine to a cluster of Azure VMs. Use an existing compute target from azureml.core import ComputeTarget compute_target = ComputeTarget ( workspace = ws , name = \"<compute-name>\" ) Create a compute target For example, to create a new cluster of between 0 and 4 \"Standard_NC24rs_v3\" VMs: from azureml.core import ComputeTarget from azureml.core.compute import AmlCompute compute_config = AmlCompute . provisioning_configuration ( vm_size = \"Standard_NC24rs_v3\" , min_nodes = 0 , max_nodes = 4 , ) compute_target = ComputeTarget . create ( ws , \"<compute-name>\" , compute_config ) compute_target . wait_for_completion ( show_output = True ) See the Compute Targets page for more examples. Environment The Environment class is used to configure reproducable Python environments for use throughout AML. These environments are versioned and sharable. Creating AML Environments. From existing Conda environment Create an AML Environment from an existing local conda environment: from azureml.core import Environment env = Environment . from_existing_conda_environment ( name = \"<aml-environment-name>\" , conda_environment_name = \"<conda_environment_name>\" , ) Conda local environments To see your local Conda environments run conda env list For more information, see Managing environments in the conda user guide. From Conda `env.yml` file Create an AML Environment from a conda env.yml file: from azureml.core import Environment my_env = Environment . from_conda_specification ( name = '<environment-name>' , file_path = '<path-to-env.yml>' , # relative paths are okay ) Configure conda environments with env.yml files Conda environments can be specified by way of an env.yml file, e.g. name: example dependencies: - numpy - pandas For more information, see Managing environments in the conda user guide. From pip `requirements.txt` file To create an AML environment from a pip requirement.txt file: from azureml.core import Environment env = Environment . from_pip_specification ( name = '<environment-name>' , file_path = '<path-to-requirements.txt>' , ) Configure pip environments with requirements.txt files Requirements files are pip's way configuring Python environments. For more information, see Requirements file in the pip user guide. Registering AML Environments. To register this environment with the workspace env . register ( ws ) # can be accessed by any user of the workspace To view all environments registered to a workspace from azureml.core import Environment registered_environments = Environment . list ( ws ) Working with data in AzureML Datastore Get datastore Each workspace comes with a default datastore. ds = ws . get_default_datastore () Any datastore that is registered to workspace can be accessed by name. from azureml.core import Datastore ds = Datastore . get ( ws , \"<name-of-registered-datastore>\" ) Register a datastore Register a datastore via a SAS token. ds = Datastore . register_azure_blob_container ( workspace = ws , datastore_name = \"<datastore-name>\" , container_name = \"<container-name>\" , account_name = \"<account-name>\" , sas_token = \"<sas-token>\" , ) For more ways authentication options and for different underlying storage see the AML documentation on Datastores . Dataset A Dataset is a reference to data in a Datastore or behind public web urls. Create a dataset from azureml.core import Dataset dataset = Dataset . Tabular . from_delimited_files ( path = [( datastore , 'train-dataset/tabular/iris.csv' )]) Preview a dataset # preview the first 3 rows of the dataset dataset . take ( 3 ) . to_pandas_dataframe () Running Scripts in AML To run code in AML you need to: Configure : Configuration includes specifying the code to run, the compute target to run on and the Python environment to run in. Submit : Create or reuse an AML Experiment and submit the run. ScriptRunConfig A typical directory may have the following structure: source_directory/ script.py # entry point to your code module1.py # modules called by script.py ... ScriptRunConfig: Basic from azureml.core import ScriptRunConfig config = ScriptRunConfig ( source_directory = '<path/to/source_directory>' , # relative paths okay script = 'script.py' , ) ScriptRunConfig:Command line arguments script.py may be set up to accept command line arguments, e.g., python script.py --argument 42 --another_argument 73 In that case we pass the arguments list to config : from azureml.core import ScriptRunConfig config = ScriptRunConfig ( source_directory = '<path/to/source_directory>' , script = 'script.py' , arguments = [ 'argument' , 42 , 'another_argument' , 73 , ], ) ScriptRunConfig: ComputeTarget By default this configuration will run on local compute. To use AML compute target specify in the run_config attribute: from azureml.core import ComputeTarget compute_target = ComputeTarget ( workspace = ws , name = \"<compute-name>\" ) config . run_config . target = target # of type azureml.core.ComputeTarget See Compute Targets for creating and accessing AML ComputeTargets. ScriptRunConfig: Environment If your script requires a specific Python environment to run: specify in the run_config attribute: from azureml.core import Environment env = Environment ( ws , '<environment-name>' ) config . run_config . environment = env # of type azureml.core.Environment See Environment for managing AML Environments. ScriptRunConfig: Submit Submit this configuration to run as part of an Experiment. from azureml.core import Experiment exp = Experiment ( ws , \"<experiment-name>\" ) # get or create Experiment run = exp . submit ( config ) # submit config to run in AML # returns Run object Logging Logging metrics To log metrics in your running script add the following: from azureml.core import Run run = Run . get_context () run . log ( \"metric-name\" , metric_value ) Viewing metrics with the Python SDK Viewing metrics in a run metrics = run . get_metrics () # metrics is of type Dict[str, List[float]] mapping mertic names # to a list of the values for that metric in the given run. metrics . get ( \"metric-name\" ) # list of metrics in the order they were recorded To view all recorded values for a given metric my-metric in a given experiment my-experiment : experiments = ws . experiments # of type Dict[str, Experiment] mapping experiment names the # corresponding Experiment exp = experiments [ 'my-experiment' ] for run in exp . get_runs (): metrics = run . get_metrics () my_metric = metrics . get ( 'my-metric' ) if my_metric : print ( my_metric )","title":"Cheatsheet"},{"location":"#azure-ml-cheat-sheet","text":"","title":"Azure ML Cheat Sheet"},{"location":"#basic-objects","text":"","title":"Basic Objects"},{"location":"#workspace","text":"","title":"Workspace"},{"location":"#creating-a-new-workspace","text":"To create a new Workspace : from azureml.core import Workspace ws = Workspace . create ( name = '<my-workspace-name>' , resource_group = '<my-resource-group>' , subscription_id = '<azure-subscription-id>' , location = '<azure-region>' , # e.g. 'eastus2' create_resource_group =< True / False > , # default:True sku = 'basic/enterprise' , # default:'basic' exists_ok =< True / False > , # default:False ) Supported Azure Regions See list of supported Azure regions here Write the workspace Azure Resource Manager (ARM) properties to a config file: ws . write_config ( path = '.azureml' , file_name = 'config.json' ) Workspace ARM properties can be loaded later using from_config() method. The path defaults to '.azureml/' and the file_name defaults to 'config.json'.","title":"Creating a new Workspace"},{"location":"#instantiate-a-workspace","text":"Instantiate a workspace with the explicit Azure Resource Manager (ARM) properties: from azureml.core import Workspace ws = Workspace . get ( subscription_id = '<subscription-id>' , resource_group = '<resource-group>' , workspace_name = '<workspace-name>' , ) Instantiate a workspace from config file: from azureml.core import Workspace ws = Workspace . from_config ( path = '.azureml' ) # read your aml credentials from config.json and instantiate # Workspace object from_config search path By default, from_config() will search for a file named config.json in the current and parent directories and in any directory named .azureml therein. Otherwise the path and _file_name need to be provided.","title":"Instantiate a Workspace"},{"location":"#delete-a-workspace","text":"To delete an Azure Machine Learning workspace: ws . delete ( delete_dependent_resources = False , # delete all resources associated to the ws no_wait = False , # whether to wait for the deletion to complete ) Workspaces Workspaces are a foundational object used throughout AML and are used in the constructors of many other classes. In the following examples we frequently omit the workspace object instantiation and simply refer to ws . See the workspaces page for more ways to instantiate a workspace.","title":"Delete a Workspace"},{"location":"#experiment","text":"An experiment is used as an organizational principle, storing run history and tracking metrics.","title":"Experiment"},{"location":"#get-all-experiments-within-a-workspace","text":"from azureml.core import Experiment experiments = Experiment . list ( ws , tags = None ) # return list[Experiment]","title":"Get all experiments within a workspace"},{"location":"#get-or-create-an-experiment","text":"from azureml.core import Experiment exp = Experiment ( ws , '<experiment-name>' ) If the experiment is not found in the workspace, a new experiment is created. Experiment names Experiment name must be 3-36 characters, start with a letter or a number, and can only contain letters, numbers, underscores, and dashes.","title":"Get or create an experiment"},{"location":"#manage-experiments","text":"Archive an experiment: exp . archive () Reactivate an experiment: exp . reactivate () Rename an experiment: exp = Experiment ( ws , name = '<exp-name>' ) exp . archive () exp . reactivate ( new_name = '<new-name>' )","title":"Manage experiments"},{"location":"#get-all-runs-within-an-experiment","text":"Get a generator of all the runs contained in an experiment: exp . get_runs () # return list[Run] Get only runs of a certain type or with certain tags: exp . get_runs ( type = 'hyperdrive' , tags = { 'modifiedBy' : 'Master CI' }) # return list[Run] Run types Run type (str) indicates how the run was created. Examples include 'hyperdrive' or 'azureml.scriptrun', but can be extended with custom types. Get run include child runs: exp . get_runs ( include_children = True ) # return list[Run]","title":"Get all runs within an experiment"},{"location":"#tag-an-experiment","text":"Tags on an experiment are stored in a dictionary with string keys and string values. Tag an experiment: exp . tag ( '' ) exp . tag ( 'DeploymentCandidate' ) exp . tag ( 'modifiedBy' , 'Master CI' ) exp . tag ( 'modifiedBy' , 'release pipeline' ) # careful, tags are mutable OR: # add a set of tags by providing Dict[str,str] exp . set_tags ({ 'modifiedBy' : 'Master CI' , 'area' : 'nlp' })","title":"Tag an experiment"},{"location":"#run","text":"A run represents a single trial of an experiment. Runs are used to monitor the asynchronous execution of a trial, log metrics and store output of the trial, and to analyze results and access artifacts generated by the trial. Run IDs A unique run_id is automatically generated for each run.","title":"Run"},{"location":"#create-a-run","text":"There are multiple ways to create a run. For example: Interactive run Create interactive runs in an interactive scenario e.g. Jupyter notebooks. from azureml.core import Experiment exp = Experiment ( ws , \"<experiment-name>\" ) # get or create experiment run = exp . start_logging () # start interactive run result = my_function () # do some things... run . log ( 'result' , result ) # log the results to the run run . complete () # stop the interactive run Logging See Logging . From configuration To submit a run asynchronously - either to local compute or to cloud compute - define a configuration. See \" Running Scripts in AML \" for details. from azureml.core import Experiment from azureml.core import ScriptRunConfig exp = Experiment ( ws , \"<experiment-name>\" ) config = ScriptRunConfig ( ... ) # provide code, compute, environments, etc. run = exp . submit ( config ) ScriptRunConfig See Running Scripts in AML .","title":"Create a run"},{"location":"#get-list-of-runs","text":"List of runs within an experiment: from azureml.core import Experiment from azureml.core import Run exp = Experiment ( ws , name = '<experiment-name>' ) runs = Run . list ( exp ) # return Generator[Run] List of runs within a compute target: from azureml.core import ComputeTarget from azureml.core import Run target = ComputeTarget ( ws , name = '<target-name>' ) runs_on_target = Run . list_by_compute ( target ) # return Generator[Run] Filtered list of runs: from azureml.core import Run type_ = 'hyperdrive' tags = { 'area' : 'nlp' } status = 'Completed' runs = Run . list ( exp , type = type_ , tags = tags , status = status ) # return Generator[Run] Run types Run type (str) indicates how the run was created. Examples include 'hyperdrive' or 'azureml.scriptrun', but can be extended with custom types.","title":"Get list of runs"},{"location":"#managing-runs","text":"Get run status: run . get_status () Cancel a run: run . cancel () Mark run as failed: run . fail ( error_details = 'userError' ) # error details can be str run . fail ( error_details = TypeError ) # or BaseException","title":"Managing runs"},{"location":"#get-run-details","text":"Get the definition, status information, current log files, and other details of the run. run . get_details () # return dict[str, str] Keys: runId , target , status , startTimeUtc , endTimeUtc , properties , datasets , logfiles . For more details see the method signature .","title":"Get run details"},{"location":"#compute-target","text":"Compute targets are an AML abstraction around the concept of a compute resource. This can range from your local machine to a cluster of Azure VMs.","title":"Compute Target"},{"location":"#use-an-existing-compute-target","text":"from azureml.core import ComputeTarget compute_target = ComputeTarget ( workspace = ws , name = \"<compute-name>\" )","title":"Use an existing compute target"},{"location":"#create-a-compute-target","text":"For example, to create a new cluster of between 0 and 4 \"Standard_NC24rs_v3\" VMs: from azureml.core import ComputeTarget from azureml.core.compute import AmlCompute compute_config = AmlCompute . provisioning_configuration ( vm_size = \"Standard_NC24rs_v3\" , min_nodes = 0 , max_nodes = 4 , ) compute_target = ComputeTarget . create ( ws , \"<compute-name>\" , compute_config ) compute_target . wait_for_completion ( show_output = True ) See the Compute Targets page for more examples.","title":"Create a compute target"},{"location":"#environment","text":"The Environment class is used to configure reproducable Python environments for use throughout AML. These environments are versioned and sharable. Creating AML Environments. From existing Conda environment Create an AML Environment from an existing local conda environment: from azureml.core import Environment env = Environment . from_existing_conda_environment ( name = \"<aml-environment-name>\" , conda_environment_name = \"<conda_environment_name>\" , ) Conda local environments To see your local Conda environments run conda env list For more information, see Managing environments in the conda user guide. From Conda `env.yml` file Create an AML Environment from a conda env.yml file: from azureml.core import Environment my_env = Environment . from_conda_specification ( name = '<environment-name>' , file_path = '<path-to-env.yml>' , # relative paths are okay ) Configure conda environments with env.yml files Conda environments can be specified by way of an env.yml file, e.g. name: example dependencies: - numpy - pandas For more information, see Managing environments in the conda user guide. From pip `requirements.txt` file To create an AML environment from a pip requirement.txt file: from azureml.core import Environment env = Environment . from_pip_specification ( name = '<environment-name>' , file_path = '<path-to-requirements.txt>' , ) Configure pip environments with requirements.txt files Requirements files are pip's way configuring Python environments. For more information, see Requirements file in the pip user guide. Registering AML Environments. To register this environment with the workspace env . register ( ws ) # can be accessed by any user of the workspace To view all environments registered to a workspace from azureml.core import Environment registered_environments = Environment . list ( ws )","title":"Environment"},{"location":"#working-with-data-in-azureml","text":"","title":"Working with data in AzureML"},{"location":"#datastore","text":"","title":"Datastore"},{"location":"#get-datastore","text":"Each workspace comes with a default datastore. ds = ws . get_default_datastore () Any datastore that is registered to workspace can be accessed by name. from azureml.core import Datastore ds = Datastore . get ( ws , \"<name-of-registered-datastore>\" )","title":"Get datastore"},{"location":"#register-a-datastore","text":"Register a datastore via a SAS token. ds = Datastore . register_azure_blob_container ( workspace = ws , datastore_name = \"<datastore-name>\" , container_name = \"<container-name>\" , account_name = \"<account-name>\" , sas_token = \"<sas-token>\" , ) For more ways authentication options and for different underlying storage see the AML documentation on Datastores .","title":"Register a datastore"},{"location":"#dataset","text":"A Dataset is a reference to data in a Datastore or behind public web urls.","title":"Dataset"},{"location":"#create-a-dataset","text":"from azureml.core import Dataset dataset = Dataset . Tabular . from_delimited_files ( path = [( datastore , 'train-dataset/tabular/iris.csv' )])","title":"Create a dataset"},{"location":"#preview-a-dataset","text":"# preview the first 3 rows of the dataset dataset . take ( 3 ) . to_pandas_dataframe ()","title":"Preview a dataset"},{"location":"#running-scripts-in-aml","text":"To run code in AML you need to: Configure : Configuration includes specifying the code to run, the compute target to run on and the Python environment to run in. Submit : Create or reuse an AML Experiment and submit the run.","title":"Running Scripts in AML"},{"location":"#scriptrunconfig","text":"A typical directory may have the following structure: source_directory/ script.py # entry point to your code module1.py # modules called by script.py ... ScriptRunConfig: Basic from azureml.core import ScriptRunConfig config = ScriptRunConfig ( source_directory = '<path/to/source_directory>' , # relative paths okay script = 'script.py' , ) ScriptRunConfig:Command line arguments script.py may be set up to accept command line arguments, e.g., python script.py --argument 42 --another_argument 73 In that case we pass the arguments list to config : from azureml.core import ScriptRunConfig config = ScriptRunConfig ( source_directory = '<path/to/source_directory>' , script = 'script.py' , arguments = [ 'argument' , 42 , 'another_argument' , 73 , ], ) ScriptRunConfig: ComputeTarget By default this configuration will run on local compute. To use AML compute target specify in the run_config attribute: from azureml.core import ComputeTarget compute_target = ComputeTarget ( workspace = ws , name = \"<compute-name>\" ) config . run_config . target = target # of type azureml.core.ComputeTarget See Compute Targets for creating and accessing AML ComputeTargets. ScriptRunConfig: Environment If your script requires a specific Python environment to run: specify in the run_config attribute: from azureml.core import Environment env = Environment ( ws , '<environment-name>' ) config . run_config . environment = env # of type azureml.core.Environment See Environment for managing AML Environments. ScriptRunConfig: Submit Submit this configuration to run as part of an Experiment. from azureml.core import Experiment exp = Experiment ( ws , \"<experiment-name>\" ) # get or create Experiment run = exp . submit ( config ) # submit config to run in AML # returns Run object","title":"ScriptRunConfig"},{"location":"#logging","text":"","title":"Logging"},{"location":"#logging-metrics","text":"To log metrics in your running script add the following: from azureml.core import Run run = Run . get_context () run . log ( \"metric-name\" , metric_value )","title":"Logging metrics"},{"location":"#viewing-metrics-with-the-python-sdk","text":"Viewing metrics in a run metrics = run . get_metrics () # metrics is of type Dict[str, List[float]] mapping mertic names # to a list of the values for that metric in the given run. metrics . get ( \"metric-name\" ) # list of metrics in the order they were recorded To view all recorded values for a given metric my-metric in a given experiment my-experiment : experiments = ws . experiments # of type Dict[str, Experiment] mapping experiment names the # corresponding Experiment exp = experiments [ 'my-experiment' ] for run in exp . get_runs (): metrics = run . get_metrics () my_metric = metrics . get ( 'my-metric' ) if my_metric : print ( my_metric )","title":"Viewing metrics with the Python SDK"},{"location":"templates/","text":"Templates Introduction Cookiecutter is a simple command-line tool that allows you to quickly create new projects from pre-defined templates. Let's see it in action! First go ahead and get cookiecutter using your environment manager of choice, for example: pip install cookiecutter Then give this repo a home cd ~/repos # or wherever your repos call home :-) git clone <this-repo> To create a new project from the ScriptRunConfig template for example, simply run cookiecutter path/to/cheatsheet/repo/templates/ScriptRunConfig See ScriptRunConfig for more details for this template. Templates ScriptRunConfig: Create a project to run a script in AML making use of the ScriptRunConfig class. This template is well suited for smaller projects and is especially handy for testing. ScriptRunConfig Cookiecutter template for setting up an AML ScriptRunConfig used to run your script in Azure. Usage Run the cookiecutter command cookiecutter <path/to/cookiecutter/templates>/ScriptRunConfig to create a new ScriptRunConfig project. Note. Install with pip install cookiecutter (see cookiecutter docs for more installation options) You will be prompted for the following: directory_name : The desired name of the directory (default: \"aml-src-script\") script_name : The name of the python script to be run in Azure (default: \"script\") subscription_id : Your Azure Subscription ID resource_group : Your Azure resource group name workspace_name : Your Azure ML workspace name compute_target_name : The name of the Azure ML compute target to run the script on (default: \"local\", will run on your box) Cookiecutter creates a new project with the following layout. {directory_name}/ {script_name}.py # the script you want to run in the cloud run.py # wraps your script in ScriptRunConfig to send to Azure config.json # your Azure ML metadata readme.md # this readme file! See ScriptRunConfig for more options and details on configuring runs.","title":"Templates"},{"location":"templates/#templates","text":"","title":"Templates"},{"location":"templates/#introduction","text":"Cookiecutter is a simple command-line tool that allows you to quickly create new projects from pre-defined templates. Let's see it in action! First go ahead and get cookiecutter using your environment manager of choice, for example: pip install cookiecutter Then give this repo a home cd ~/repos # or wherever your repos call home :-) git clone <this-repo> To create a new project from the ScriptRunConfig template for example, simply run cookiecutter path/to/cheatsheet/repo/templates/ScriptRunConfig See ScriptRunConfig for more details for this template.","title":"Introduction"},{"location":"templates/#templates_1","text":"ScriptRunConfig: Create a project to run a script in AML making use of the ScriptRunConfig class. This template is well suited for smaller projects and is especially handy for testing.","title":"Templates"},{"location":"templates/#scriptrunconfig","text":"Cookiecutter template for setting up an AML ScriptRunConfig used to run your script in Azure.","title":"ScriptRunConfig"},{"location":"templates/#usage","text":"Run the cookiecutter command cookiecutter <path/to/cookiecutter/templates>/ScriptRunConfig to create a new ScriptRunConfig project. Note. Install with pip install cookiecutter (see cookiecutter docs for more installation options) You will be prompted for the following: directory_name : The desired name of the directory (default: \"aml-src-script\") script_name : The name of the python script to be run in Azure (default: \"script\") subscription_id : Your Azure Subscription ID resource_group : Your Azure resource group name workspace_name : Your Azure ML workspace name compute_target_name : The name of the Azure ML compute target to run the script on (default: \"local\", will run on your box) Cookiecutter creates a new project with the following layout. {directory_name}/ {script_name}.py # the script you want to run in the cloud run.py # wraps your script in ScriptRunConfig to send to Azure config.json # your Azure ML metadata readme.md # this readme file! See ScriptRunConfig for more options and details on configuring runs.","title":"Usage"},{"location":"more/compute-targets/","text":"Compute Targets The following will first attempt to retrieve an existing compute target by its name. If the compute does not exist it will create the cluster. from azureml.core import ComputeTarget from azureml.core.compute import AmlCompute from azureml.core.compute_target import ComputeTargetException compute_name = \"<compute-name>\" try : compute_target = ComputeTarget ( workspace = ws , name = compute_name ) print ( f 'Found existing compute target: { compute_name } .' ) except ComputeTargetException : print ( 'Creating a new compute target...' ) compute_target = ComputeTarget . create ( ws , compute_name , compute_config ) compute_target . wait_for_completion ( show_output = True )","title":"Compute Targets"},{"location":"more/compute-targets/#compute-targets","text":"The following will first attempt to retrieve an existing compute target by its name. If the compute does not exist it will create the cluster. from azureml.core import ComputeTarget from azureml.core.compute import AmlCompute from azureml.core.compute_target import ComputeTargetException compute_name = \"<compute-name>\" try : compute_target = ComputeTarget ( workspace = ws , name = compute_name ) print ( f 'Found existing compute target: { compute_name } .' ) except ComputeTargetException : print ( 'Creating a new compute target...' ) compute_target = ComputeTarget . create ( ws , compute_name , compute_config ) compute_target . wait_for_completion ( show_output = True )","title":"Compute Targets"},{"location":"more/datastore/","text":"","title":"Datastore"},{"location":"more/environment/","text":"Environment From conda/pip files We can use a Conda/pip to define AML environments. Conda (env.yml) # env.yml name: my-env channels: - defaults - conda-forge dependencies: - numpy - pandas - scipy - scikit-learn - pip - python=3.6 - jupyter - ipykernel - pip: - azureml-sdk==1.8.0 - torch - transformers==2.11.0 pip (requirements.txt) # requirement.txt azureml-dataprep==1.8.3 azureml-sdk==1.8.0 flake8==3.7.9 numpy==1.18.5 pycodestyle==2.5.0 torch==1.5.1 tqdm==4.48.0 transformers==2.11.0 to create and register an AML environment that can be cached, versioned and reused between different experiments, runs and compute targets. Create the AML environment Conda from azureml.core import Environment my_env = Environment . from_conda_specification ( name = '<environment-name>' , file_path = '<path-to-env.yml>' , ) pip from azureml.core import Environment my_env = Environment . from_pip_specification ( name = '<environment-name>' , file_path = '<path-to-requirements.txt>' , ) To register this environment with the workspace my_env . register ( ws ) To view all environments registered to a workspace from azureml.core import Environment registered_environments = Environment . list ( ws ) Specifying dependencies TODO","title":"Environment"},{"location":"more/environment/#environment","text":"","title":"Environment"},{"location":"more/environment/#from-condapip-files","text":"We can use a Conda/pip to define AML environments. Conda (env.yml) # env.yml name: my-env channels: - defaults - conda-forge dependencies: - numpy - pandas - scipy - scikit-learn - pip - python=3.6 - jupyter - ipykernel - pip: - azureml-sdk==1.8.0 - torch - transformers==2.11.0 pip (requirements.txt) # requirement.txt azureml-dataprep==1.8.3 azureml-sdk==1.8.0 flake8==3.7.9 numpy==1.18.5 pycodestyle==2.5.0 torch==1.5.1 tqdm==4.48.0 transformers==2.11.0 to create and register an AML environment that can be cached, versioned and reused between different experiments, runs and compute targets. Create the AML environment Conda from azureml.core import Environment my_env = Environment . from_conda_specification ( name = '<environment-name>' , file_path = '<path-to-env.yml>' , ) pip from azureml.core import Environment my_env = Environment . from_pip_specification ( name = '<environment-name>' , file_path = '<path-to-requirements.txt>' , ) To register this environment with the workspace my_env . register ( ws ) To view all environments registered to a workspace from azureml.core import Environment registered_environments = Environment . list ( ws )","title":"From conda/pip files"},{"location":"more/environment/#specifying-dependencies","text":"TODO","title":"Specifying dependencies"},{"location":"more/workspace/","text":"Workspace Instantiate workspace. from azureml.core import Workspace ws = Workspace . from_config () This examples reads the workspace from a config.json file, the contents of which are of the form { \"subscription_id\" : <subscription-id> , \"resource_group\" : <resource-group> , \"workspace_name\" : <workspace-name> } Alternatively you can provide these values directly: from azureml.core import Workspace ws = Workspace . get ( name = \"<workspace-name>\" , subscription_id = \"<subscription-id>\" , resource_group = \"<resource-group>\" , )","title":"Workspace"},{"location":"more/workspace/#workspace","text":"Instantiate workspace. from azureml.core import Workspace ws = Workspace . from_config () This examples reads the workspace from a config.json file, the contents of which are of the form { \"subscription_id\" : <subscription-id> , \"resource_group\" : <resource-group> , \"workspace_name\" : <workspace-name> } Alternatively you can provide these values directly: from azureml.core import Workspace ws = Workspace . get ( name = \"<workspace-name>\" , subscription_id = \"<subscription-id>\" , resource_group = \"<resource-group>\" , )","title":"Workspace"},{"location":"vs-code-snippets/snippets/","text":"VS Code Snippets We have compiled a collection of VS code snippets designed to make it easy to work with Azure ML. To add these snippets to your VS Code: ctrl+shift+p > Type \"Configure user snippets\" > Select python.json . All of these snippets are available here: python.json Basic core imports \"Basic core imports\" : { \"prefix\" : \"workspace-imports-creation\" , \"body\" : [ \"from azureml.core import Workspace, Experiment, Run, RunConfiguration, ComputeTarget$1\" , \"$0\" ], \"description\" : \"Import essential packages\" } Pipeline imports \"Pipeline Imports\" : { \"prefix\" : \"pipeline-imports\" , \"body\" : [ \"from azureml.pipeline.core import Pipeline, PipelineData, PipelineParameter\" , \"from azureml.pipeline.steps import PythonScriptStep$1\" , \"$0\" ], \"description\" : \"Basic imports for pipeline\" } Create AML Workspace from config \"Create AML Workspace from config\" : { \"prefix\" : [ \"workspace-quick\" , \"fromconfig\" , \"from-config\" ], \"body\" : [ \"ws = Workspace.from_config()\" , \"$0\" ], \"description\" : \"Default workspace creation\" } Create AML Workspace from config and auth \"Create AML Workspace from config and auth\" : { \"prefix\" : \"workspace-from-config-auth\" , \"body\" : [ \"from azureml.core.authentication import InteractiveLoginAuthentication\" , \"config = {'subscription_id':'$1',\" , \"'resource_group':'$2',\" , \"'workspace_name' :'$3'}\" , \"auth = InteractiveLoginAuthentication()\" , \"ws = Workspace(**config,auth = auth)\" , \"$0\" ], \"description\" : \"Create workspace from config and auth\" } Register Azure Blob Container From SAS \"Register Azure Blob Container From SAS\" : { \"prefix\" : [ \"datastore-register-blob-sas\" , \"reg-blob-sas\" ], \"body\" : [ \"ds = Datastore.register_azure_blob_container(\" \" workspace='$1',\" \" datastore_name='$2',\" , \" container_name='$3',\" , \" account_name='$4',\" , \" sas_token='$5',\" , \")\" \"$0\" ], \"description\" : \"Register Azure Blob container to workspace via SAS\" } Create Compute Cluster with SSH \"Create Compute Cluster with SSH\" : { \"prefix\" : [ \"create-compute-cluster-ssh\" ], \"body\" : [ \"from azureml.core.compute import AmlCompute\" , \"from azureml.core.compute_target import ComputeTargetException\" , \"ssh_public_key = '$1'\" , \"compute_config = AmlCompute.provisioning_configuration(vm_size='$4',min_nodes=$5, max_nodes=$6,admin_username='$7',admin_user_ssh_key=ssh_public_key,vm_priority='${8|lowpriority,dedicated|}',remote_login_port_public_access='Enabled')\" , \"cluster$0 = ComputeTarget.create(workspace=$9, name='$10', compute_config)\" ], \"description\" : \"Create compute cluster with SSH enabled\" }","title":"VS Code Snippets"},{"location":"vs-code-snippets/snippets/#vs-code-snippets","text":"We have compiled a collection of VS code snippets designed to make it easy to work with Azure ML. To add these snippets to your VS Code: ctrl+shift+p > Type \"Configure user snippets\" > Select python.json . All of these snippets are available here: python.json","title":"VS Code Snippets"},{"location":"vs-code-snippets/snippets/#basic-core-imports","text":"\"Basic core imports\" : { \"prefix\" : \"workspace-imports-creation\" , \"body\" : [ \"from azureml.core import Workspace, Experiment, Run, RunConfiguration, ComputeTarget$1\" , \"$0\" ], \"description\" : \"Import essential packages\" }","title":"Basic core imports"},{"location":"vs-code-snippets/snippets/#pipeline-imports","text":"\"Pipeline Imports\" : { \"prefix\" : \"pipeline-imports\" , \"body\" : [ \"from azureml.pipeline.core import Pipeline, PipelineData, PipelineParameter\" , \"from azureml.pipeline.steps import PythonScriptStep$1\" , \"$0\" ], \"description\" : \"Basic imports for pipeline\" }","title":"Pipeline imports"},{"location":"vs-code-snippets/snippets/#create-aml-workspace-from-config","text":"\"Create AML Workspace from config\" : { \"prefix\" : [ \"workspace-quick\" , \"fromconfig\" , \"from-config\" ], \"body\" : [ \"ws = Workspace.from_config()\" , \"$0\" ], \"description\" : \"Default workspace creation\" }","title":"Create AML Workspace from config"},{"location":"vs-code-snippets/snippets/#create-aml-workspace-from-config-and-auth","text":"\"Create AML Workspace from config and auth\" : { \"prefix\" : \"workspace-from-config-auth\" , \"body\" : [ \"from azureml.core.authentication import InteractiveLoginAuthentication\" , \"config = {'subscription_id':'$1',\" , \"'resource_group':'$2',\" , \"'workspace_name' :'$3'}\" , \"auth = InteractiveLoginAuthentication()\" , \"ws = Workspace(**config,auth = auth)\" , \"$0\" ], \"description\" : \"Create workspace from config and auth\" }","title":"Create AML Workspace from config and auth"},{"location":"vs-code-snippets/snippets/#register-azure-blob-container-from-sas","text":"\"Register Azure Blob Container From SAS\" : { \"prefix\" : [ \"datastore-register-blob-sas\" , \"reg-blob-sas\" ], \"body\" : [ \"ds = Datastore.register_azure_blob_container(\" \" workspace='$1',\" \" datastore_name='$2',\" , \" container_name='$3',\" , \" account_name='$4',\" , \" sas_token='$5',\" , \")\" \"$0\" ], \"description\" : \"Register Azure Blob container to workspace via SAS\" }","title":"Register Azure Blob Container From SAS"},{"location":"vs-code-snippets/snippets/#create-compute-cluster-with-ssh","text":"\"Create Compute Cluster with SSH\" : { \"prefix\" : [ \"create-compute-cluster-ssh\" ], \"body\" : [ \"from azureml.core.compute import AmlCompute\" , \"from azureml.core.compute_target import ComputeTargetException\" , \"ssh_public_key = '$1'\" , \"compute_config = AmlCompute.provisioning_configuration(vm_size='$4',min_nodes=$5, max_nodes=$6,admin_username='$7',admin_user_ssh_key=ssh_public_key,vm_priority='${8|lowpriority,dedicated|}',remote_login_port_public_access='Enabled')\" , \"cluster$0 = ComputeTarget.create(workspace=$9, name='$10', compute_config)\" ], \"description\" : \"Create compute cluster with SSH enabled\" }","title":"Create Compute Cluster with SSH"}]}